<!DOCTYPE html><html lang="en" class="md-theme-default"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><!--[if IE]><link rel="icon" href="/favicon.ico" /><![endif]--><script async="" src="https://www.google-analytics.com/analytics.js"></script><title>Hadoop 2.7.2 单节点与集群安装部署 | Aquariuslt Blog</title><link href="/css/about.f196d9fa.css" rel="prefetch"><link href="/css/detail.550d548d.css" rel="prefetch"><link href="/js/about.523c72d5.js" rel="prefetch"><link href="/js/detail.241ec94b.js" rel="prefetch"><link href="/css/app.4df1cf9a.css" rel="preload" as="style"><link href="/css/chunk-vendors.9bb7e852.css" rel="preload" as="style"><link href="/js/app.eff8a5d6.js" rel="preload" as="script"><link href="/js/chunk-vendors.d167db0b.js" rel="preload" as="script"><link href="/css/chunk-vendors.9bb7e852.css" rel="stylesheet"><link href="/css/app.4df1cf9a.css" rel="stylesheet"><link rel="icon" type="image/png" sizes="32x32" href="/img/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/icons/favicon-16x16.png"><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#1A73E8"><meta name="apple-mobile-web-app-capable" content="no"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="apple-mobile-web-app-title" content="Aquariuslt Blog"><link rel="apple-touch-icon" href="/img/icons/apple-touch-icon-152x152.png"><link rel="mask-icon" href="/img/icons/safari-pinned-tab.svg" color="#1A73E8"><meta name="msapplication-TileImage" content="/img/icons/msapplication-icon-144x144.png"><meta name="msapplication-TileColor" content="#000000"><link rel="stylesheet" type="text/css" href="/css/detail.550d548d.css"><script charset="utf-8" src="/js/detail.241ec94b.js"></script><meta data-vue-meta="1" name="google-site-verification" content="s3PYm0fCo0ImPqqXoPLiUb_bFdlYODKw54VGSkcFgyE"><meta data-vue-meta="1" name="google-analytics" content="UA-68904127-1"><meta data-vue-meta="1" name="og:site_name" content="Aquariuslt Blog"><meta data-vue-meta="1" name="og:type" content="website"><meta data-vue-meta="1" name="og:title" content="Hadoop 2.7.2 单节点与集群安装部署"><meta data-vue-meta="1" name="og:description" content="最近需要做一些大数据相关项目,至少需要搭建 Hadoop 的基本环境. 由于用到的是目前版本号最高的 Hadoop 2.7.2.跟文档比较多的 2.6 以下的版本相比,在部署集群的时候遇见了很多坑. 所以写一份安装指南,记录一下跌坑的过程,以示警惕.
"><meta data-vue-meta="1" name="og:image" content="./cover.png"><meta data-vue-meta="1" name="og:type" content="article"><script data-vue-meta="1" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://blog.aquariuslt.com","name":"Aquariuslt Blog","position":1},{"@type":"ListItem","item":"https://blog.aquariuslt.com/posts","name":"Posts","position":2},{"@type":"ListItem","item":"https://blog.aquariuslt.com/posts/2016/04/09/hadoop-2-7-2-single-node-and-cluster-mode-installation-guide","name":"Hadoop 2.7.2 单节点与集群安装部署","position":3}]}</script><script id="embed-disqus" data-timestamp="1572195162980" type="text/javascript" async="" src="//aquariuslt.disqus.com/embed.js"></script><link rel="prefetch" as="style" href="https://c.disquscdn.com/next/embed/styles/lounge.953a2bd009935f47a8e815c3ee2bfc5a.css"><link rel="prefetch" as="script" href="https://c.disquscdn.com/next/embed/common.bundle.9ae27258a9490b17fbb3b9cdf530aff0.js"><link rel="prefetch" as="script" href="https://c.disquscdn.com/next/embed/lounge.bundle.0adc4cfceff8c3ab4259d467d6ea3419.js"><link rel="prefetch" as="script" href="https://disqus.com/next/config.js"></head><body><div data-v-18dadf06="" id="app"><div data-v-18dadf06="" class="md-app md-app-side-drawer md-layout-row md-waterfall md-fixed md-theme-default"><div data-v-18dadf06="" class="md-drawer md-app-drawer md-theme-default md-left md-temporary"><div data-v-ac1b82fe="" data-v-18dadf06="" class="profile"><div data-v-ac1b82fe="" class="md-card md-theme-default"><div data-v-ac1b82fe="" class="md-card-header"><div data-v-ac1b82fe="" class="md-avatar md-theme-default"><img data-v-ac1b82fe="" src="https://img.aquariuslt.com/social/avator.png" alt="Avatar"></div><div data-v-ac1b82fe="" class="md-title">Aquariuslt</div><div data-v-ac1b82fe="" class="md-subhead">superaquariuslt@gmail.com</div></div></div></div><ul data-v-18dadf06="" class="md-list md-theme-default"><li data-v-18dadf06="" to="/" exact="" class="md-list-item"><a data-v-18dadf06="" href="/" class="md-list-item-router md-list-item-container md-button-clean" mdripple="true"><div class="md-list-item-content md-ripple"><i data-v-18dadf06="" class="mdi mdi-24px mdi-home"></i><span data-v-18dadf06="" class="md-list-item-text">Home</span> </div></a></li><li data-v-18dadf06="" to="/categories" exact="" class="md-list-item"><a data-v-18dadf06="" href="/categories" class="md-list-item-router md-list-item-container md-button-clean" mdripple="true"><div class="md-list-item-content md-ripple"><i data-v-18dadf06="" class="mdi mdi-24px mdi-shape"></i><span data-v-18dadf06="" class="md-list-item-text">Categories</span> </div></a></li><li data-v-18dadf06="" to="/tags" exact="" class="md-list-item"><a data-v-18dadf06="" href="/tags" class="md-list-item-router md-list-item-container md-button-clean" mdripple="true"><div class="md-list-item-content md-ripple"><i data-v-18dadf06="" class="mdi mdi-24px mdi-bookmark"></i><span data-v-18dadf06="" class="md-list-item-text">Tags</span> </div></a></li></ul> </div>  <main class="md-app-container md-flex md-layout-column md-theme-default md-scrollbar" style="padding-left: 0px;"><div data-v-18dadf06="" class="md-toolbar md-app-toolbar md-primary md-theme-default md-elevation-2 md-no-elevation" md-elevation="2" style="top: 0px;"><div data-v-18dadf06="" class="md-toolbar-row"><button data-v-18dadf06="" type="button" class="md-button md-icon-button md-theme-default" aria-label="menu"><div class="md-ripple"><div class="md-button-content"><i data-v-18dadf06="" class="mdi mdi-24px mdi-menu"></i></div> </div></button><span data-v-18dadf06="" class="md-title app-title">Hadoop 2.7.2 单节点与集群安装部署 | Aquariuslt Blog</span></div></div> <div class="md-app-scroller md-layout-column md-flex md-theme-default md-scrollbar"><div data-v-18dadf06="" class="md-content md-app-content md-flex md-theme-default"><div data-v-590589f6="" data-v-18dadf06="" class="detail md-layout md-gutter md-alignment-top-center"><div data-v-46cb6cfe="" data-v-590589f6="" class="md-layout md-gutter md-alignment-top-center md-layout-item md-size-100"><div data-v-46cb6cfe="" class="breadcrumbs"><span data-v-46cb6cfe=""><a data-v-46cb6cfe="" href="/" class="breadcrumbs-item"> Aquariuslt Blog</a><span data-v-46cb6cfe="">&gt;</span></span><span data-v-46cb6cfe=""><a data-v-46cb6cfe="" href="/posts" class="breadcrumbs-item"> Posts</a><span data-v-46cb6cfe="">&gt;</span></span><span data-v-46cb6cfe=""><a data-v-46cb6cfe="" href="/posts/2016/04/09/hadoop-2-7-2-single-node-and-cluster-mode-installation-guide" class="breadcrumbs-item router-link-exact-active router-link-active"> Hadoop 2.7.2 单节点与集群安装部署</a><!----></span></div></div><div data-v-48e13d92="" data-v-590589f6="" class="md-layout md-gutter md-alignment-top-center md-layout-item md-size-100"><div data-v-48e13d92="" class="md-card article-detail md-theme-default"><div data-v-48e13d92="" class="md-card-media article-cover"><img data-v-48e13d92="" src="/posts/2016/04/09/hadoop-2-7-2-single-node-and-cluster-mode-installation-guide/cover.png" alt="cover"></div><div data-v-48e13d92="" class="md-card-content markdown-body"><h1>Hadoop 2.7.2 单节点与集群安装部署</h1>
<h2>Background</h2>
<p>最近需要做一些大数据相关项目,至少需要搭建 Hadoop 的基本环境. 由于用到的是目前版本号最高的 Hadoop 2.7.2.跟文档比较多的 2.6 以下的版本相比,在部署集群的时候遇见了很多坑. 所以写一份安装指南,记录一下跌坑的过程,以示警惕.</p>
<h2>Table Of Content</h2>
<p>暂不讨论 Hadoop 及基于其应用的场景描述,文本只讨论基本的环境搭建步骤和与之涉及的知识点. 按照顺序总结出本文的内容节点.</p>
<ol>
<li>
<p>宏观了解在集群上部署 Hadoop 的过程</p>
</li>
<li>
<p>虚拟机基本网络配置与机器配置</p>
</li>
<li>
<p>下载并解压 Hadoop</p>
</li>
<li>
<p>创建专为运行 Hadoop 的用户</p>
</li>
<li>
<p>环境变量的设定</p>
</li>
<li>
<p>修改 Hadoop 配置文件</p>
</li>
<li>
<p>启动 Hadoop 服务</p>
</li>
<li>
<p>防跌坑指南</p>
</li>
</ol>
<h2>Environment Setup</h2>
<h3>Overview: How Developer deploy Hadoop in cluster mode</h3>
<p>通常来说,一个运维工程师是如何部署一个 Hadoop 集群呢? 集群可以当成 1 台 Master 机器和多台 Slaves 机器. 在全新的 Linux 机器群中创建 Hadoop 集群,按我的理解可以分成以下几步.</p>
<ol>
<li>在 Master 上下载 Hadoop,并修改对应的 Hadoop 配置文件.</li>
<li>将修改好配置的 Hadoop 目录打包,分发到各个 Slave 中,解压到固定的执行目录.</li>
<li>修改所有机器的 hosts 文件,将局域网中的所有 ip-hostname 进行 mapping.</li>
<li>在所有机器上安装 ssh,Master 和 Slaves 之间将通过 ssh 进行运行时的通讯控制.</li>
<li>在 Master 上启动 Hadoop 服务.统一管理所有 Slave 节点.</li>
</ol>
<h3>Network and Information about Virtual Machine</h3>
<p>因为只是实验集群的部署,所以没有用到真机. 实际上虚拟机内部的多台机器所组成的集群,其实总的 I/O 还是会被物理机器限制.</p>
<p>我将使用的是 1 台 Master 和两台 Slaves 三台机器都是<code>vmware</code>上的虚拟机,网络方式都是以 NAT 桥接具体的配置如下:</p>
<ul>
<li>
<p>Master: ip:192.168.239.142 hostname:elementary-os cpu:4 core ram:16G</p>
</li>
<li>
<p>Slaves: ip:192.168.239.144,192.168.239.145 hostname:hd-worker-a,hd-worker-b cpu:1 core ram:4G harddisk:20G</p>
</li>
</ul>
<p>P.S. Master 和 Slaves 都是基于 64 位的<code>Ubuntu14.04.3LTS</code>内核的 Linux. 可以视为都是通过直接安装<code>Ubuntu14.04.3.LTS</code>.</p>
<p>为了通过<code>/etc/hosts</code>文件通过机器名访问对应的 ip, 在每一个节点上面都修改对应的<code>/etc/hosts</code>文件,将集群中所有节点加到文件里面</p>
<pre><code class="hljs bash">$ sudo vi /etc/hosts
</code></pre>
<p>在文件底部添加以下几行(实际操作中,请将 hostname 替换成自己实际机器的 hostname 与 ip)</p>
<pre><code># Hadoop Cluster Setup
## Master
192.168.239.142   elementary-os

## Slaves
192.168.239.144   hd-worker-a
192.168.239.145   hd-worker-b
</code></pre>
<h3>Download Hadoop</h3>
<p>下载地址:<a href="https://mirrors.noc.im/apache/hadoop/common/current/">https://mirrors.noc.im/apache/hadoop/common/current/</a></p>
<p>下载之后,会得到一个<code>Hadoop2.7.2</code>的解压包. 在下一步章节我们将会将其移动到其他目录.</p>
<h3>Add Hadoop Group and User</h3>
<p>在所有节点上都创建一个名为<code>hduser</code>的 user,并将其加到 sudo 列表里面. 在接下来的所有 bash 命令,默认都通过该创建的<code>hduser</code>来执行.</p>
<pre><code>$ sudo addgroup hadoop
$ sudo adduser --ingroup hadoop hduser
$ sudo adduser hduser sudo
</code></pre>
<h3>Installing SSH and Copy Public Key to remote machine</h3>
<p>什么是 SSH SSH (“Secure SHell”) is a protocol for securely accessing one machine from another. Hadoop uses SSH for accessing another slaves nodes to start and manage all HDFS and MapReduce daemons. Hadoop 通过 ssh 之间来通讯和管理节点之间的通讯.</p>
<pre><code>$ sudo apt-get install openssh-server
</code></pre>
<p>TIPS: 通常来说,ssh 远程到另一台安装了 ssh 的机器上,通过<code>ssh {username}@{hostname}</code>,之后输入密码便可以进入. 对于一些自动化部署的脚本来说自动输入密码,还需要在脚本里面写下密码. 怎么可能如此的不科学?</p>
<p>所以需要通过 ssh key 公钥来进行认证,达到无密码传输的过程. 假设我们需要在机器上 A 通过 ssh 远程到机器 B 且不需要密码,步骤如下:</p>
<ol>
<li>在机器 A 上生成自己的 ssh 公钥与密钥</li>
</ol>
<pre><code class="hljs bash">$ ssh-keygen -t rsa
</code></pre>
<p>此举将会在 user 目录下的<code>~/.ssh</code>文件夹创建对应的 <code>id_rsa</code>和<code>id_rsa.pub</code>文件. 其中<code>id_rsa.pub</code>就是公钥文件</p>
<ol start="2">
<li>在机器 A 上将自己的公钥复制到远程主机上</li>
</ol>
<pre><code class="hljs bash">$ ssh-copy-id {username}@B
$ {username}@B password:
$ <span class="hljs-comment">#此时输入用户密码</span>
</code></pre>
<p>此举会在远程主机 B 的对应 user 的 home/.ssh 目录下创建<code>authorized_key</code>文件. 该公钥已经信任,拥有这个公钥的 A 主机用户可以直接通过<code>ssh {username}@B</code>不输入密码而直接远程到 B</p>
<p>OK.在了解到这一步之后,大概知道一台机器的主机需要如何配置 ssh 了. 因为在 Hadoop 集群中,Master 与每一台 Slaves 都需要进行 ssh 通讯, 所以需要在 Hadoop 中每一台机器都生成自己的 ssh 公钥,然后与 Master 互相进行公钥传输动作.</p>
<p>在我自己的集群中,进行了 4 次<code>ssh-copy-id</code>操作:</p>
<ol>
<li>elementary-os -&gt; hd-worker-a</li>
<li>hd-worker-a -&gt; elementary-os</li>
<li>elementary-os -&gt; hd-worker-b</li>
<li>hd-worker-b -&gt; elementary-os</li>
</ol>
<h3>Basic Environment Setup</h3>
<p>在修改 Hadoop 的配置之前,需要进行配置的是所有节点的环境变量设置与必要的基础程序.</p>
<h4>JDK</h4>
<p>Hadoop 运行在 Java 环境中,所以每个节点都需要安装 JDK. 需要保证的是确保每一台节点上安装的 JDK 版本一致. P.S 我自己是 Master OpenJDK-8 + Slaves OpenJDK-7. 目前还是正常运行的 (顺便吐槽一下 <code>Ubuntu14.04</code>默认的 apt-get 源,相当傻逼.在不添加自己订阅的其他源的情况下连 OpenJDK8 的地址都没有,而且如果安装 Git 之类的工具,为求稳定居然用的是 1.7 以下的版本. 这也是为什么我日常开发用的是<code>elementary-os</code>,虽然也是基于 ubuntu14 的内核, 但是 elementary-os 修改了其默认的 apt 源,ui 看起来也更加顺眼)</p>
<pre><code class="hljs bash">$ sudo apt-get install openjdk-7-jdk
</code></pre>
<p>通过此举,安装的默认的 jdk 路径是<code>/usr/lib/jvm/java-7-openjdk-amd64</code>. OpenJDK8 同理. OracleJDK 也推荐复制到<code>/usr/lib/jvm</code>目录下.(守序善良 Linux 派优雅的约定之一)</p>
<p>记住这里咯.在下面我们会将这个 JDK 的目录,加到当前用户<code>hduser</code>的<code>.bashrc</code>中.</p>
<h3>Configure Hadoop</h3>
<p>终于到了这一步. 建议首先在 Master 上机器修改好 Hadoop 的配置.然后压缩该文件夹,复制到其他 Slave 节点上的同一目录.</p>
<h4>Unpack and move hadoop folder</h4>
<p>假设下载好的 hadoop-2.7.2.tar.gz 在 当前用户的<code>Downloads</code>文件夹中. 解压完毕之后,将其移动到<code>/usr/local</code>下,并更名为<code>hadoop</code></p>
<pre><code>$ mv hadoop-2.7.2 /usr/local/hadoop
</code></pre>
<h4>Update Environment File</h4>
<p>在配置 Hadoop 的过程中,下列配置文件将会被修改.</p>
<blockquote>
<p>~/.bashrc /usr/local/hadoop/etc/hadoop/slaves /usr/local/hadoop/etc/hadoop/hadoop-env.sh /usr/local/hadoop/etc/hadoop/core-site.xml /usr/local/hadoop/etc/hadoop/yarn-site.xml /usr/local/hadoop/etc/hadoop/mapred-site.xml /usr/local/hadoop/etc/hadoop/hdfs-site.xml</p>
</blockquote>
<h5>~/.bashrc</h5>
<p>还记得之前提过的 JDK 路径吗,将其配置成<code>JAVA_HOME</code> 修改当前用户的 bash 配置文件,将其加到.bashrc 的底部</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cd</span> ~
$ vi .bashrc
</code></pre>
<pre><code class="hljs sh"><span class="hljs-comment">#Hadoop variables</span>
<span class="hljs-built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/
<span class="hljs-built_in">export</span> HADOOP_INSTALL=/usr/<span class="hljs-built_in">local</span>/hadoop
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_INSTALL</span>/bin
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_INSTALL</span>/sbin
<span class="hljs-built_in">export</span> HADOOP_MAPRED_HOME=<span class="hljs-variable">$HADOOP_INSTALL</span>
<span class="hljs-built_in">export</span> HADOOP_COMMON_HOME=<span class="hljs-variable">$HADOOP_INSTALL</span>
<span class="hljs-built_in">export</span> HADOOP_HDFS_HOME=<span class="hljs-variable">$HADOOP_INSTALL</span>
<span class="hljs-built_in">export</span> YARN_HOME=<span class="hljs-variable">$HADOOP_INSTALL</span>
</code></pre>
<h5>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</h5>
<p>还是跟上面一样,需要将 JDK 的路径设置成<code>JAVA_HOME</code></p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/
</code></pre>
<h5>/usr/local/hadoop/etc/hadoop/core-site.xml</h5>
<p>在<code>&lt;configuartion&gt;&lt;/configuration&gt;</code>之间添加一个 fs.default.name,其值为 master 机器的 9000 端口. 譬如我的 master 机器是<code>elementary-os</code>,则 value 是<code>hdfs://elementary-os:9000</code> P.S.接下来的变量<code>{master-hostname}</code>请自行替换成自己的 master 的机器名.</p>
<pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.default.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://{master-hostname}:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop_store/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span>
</code></pre>
<h4>/usr/local/hadoop/etc/hadoop/yarn-site.xml</h4>
<p>在<code>&lt;configuartion&gt;&lt;/configuration&gt;</code>之间添加:</p>
<pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>{master-hostname}<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span>

</code></pre>
<h5>/usr/local/hadoop/etc/hadoop/mapred-site.xml</h5>
<p><code>mapred-site.xml</code>默认是不存在的. 但是有一份模板文件<code>mapred-site.xml.template</code>,我们将其复制并重命名成<code>mapred-site.xml</code></p>
<pre><code class="hljs bash">$ cp /usr/<span class="hljs-built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml.template /usr/<span class="hljs-built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml
</code></pre>
<p>在<code>&lt;configuartion&gt;&lt;/configuration&gt;</code>之间添加:</p>
<pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuartion</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapred.job.tracker<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>{master-hostname}:9001<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>{master-hostname}:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>{master-hostname}:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuartion</span>&gt;</span>
</code></pre>
<h5>/usr/local/hadoop/etc/hadoop/hdfs-site.xml</h5>
<p>在修改<code>hdfs-site.xml</code>这个配置文件之前,我们需要知道更多的一件事. hdfs 的块状文件,储存在一个指定的目录中. 按照官方文档的推荐,和网上一些文件夹的路径的约定,我们将这个 hdfs 的文件储存目录叫做<code>hadoop_store</code>.绝对路径为<code>/usr/local/hadoop_store</code></p>
<p>于是 hadoop 的相关文件夹就变成了两个:</p>
<blockquote>
<p>/usr/local/hadoop /usr/local/hadoop_store</p>
</blockquote>
<p>由于读写权限问题,我们需要将<code>hadoop_store</code>的权限改成任意可读可写</p>
<pre><code class="hljs bash">$ sudo mkdir -p /usr/<span class="hljs-built_in">local</span>/hadoop_store
$ sudo chmod -R 777 /usr/<span class="hljs-built_in">local</span>/hadoop_store
</code></pre>
<p>然后再在配置文件里面加入</p>
<pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuartion</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>{master-hostname}:50090<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop_store/hdfs/namenode<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop_store/hdfs/datanode<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuartion</span>&gt;</span>
</code></pre>
<h5>slaves</h5>
<p><code>slaves</code>文件里面存储的是作为 slave 的节点的机器名. 以行为单位,一行一个. 默认只有一行 localhost. 从一般的集群角度来说,Master 不应该担当 Worker 的角色(老湿布置作业给小学僧,自己是不会一起做作业的) 所以 slaves 文件一般只写 slave 节点的名字,即 slave 节点作为 datanode,master 节点仅仅作为 namenode.</p>
<p>但是由于我是一名好老湿,所以在本机配置中 master 也充当了 worker 的角色,所以本机是这样改的:</p>
<pre><code>elementary-os
hd-worker-a
hd-worker-b
</code></pre>
<p>致此,所有的配置文件已经修改完毕. 可以将 master 上的 hadoop 文件夹压缩并且分发到各个 slave 节点上.</p>
<h4>Last Configure : Format Namenode</h4>
<p>最后一步配置,初始格式化 hdfs</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cd</span> /usr/<span class="hljs-built_in">local</span>/hadoop/
$ hdfs namenode -format
</code></pre>
<h3>Start all Hadoop deamons</h3>
<p>启动 Hadoop 服务.</p>
<pre><code class="hljs bash">$ su hduser
$ <span class="hljs-built_in">cd</span> /usr/<span class="hljs-built_in">local</span>/hadoop/
$ sbin/start-dfs.sh
$ sbin/start-yarn.sh
</code></pre>
<p>如果启动成功,在 master 节点上通过 jps 命令查看,应该包含如下 hadoop 进程</p>
<pre><code>hduser@elementary-os:~$ jps
51288 Jps
22914 ResourceManager
22361 NameNode
23229 NodeManager
22719 SecondaryNameNode
</code></pre>
<p>在 slave 节点上通过 jps 命令查看,应该包含如下 hadoop 进程</p>
<pre><code>hduser@hd-worker-a:~$ jps
6284 NodeManager
6150 DateNode
6409 Jps
</code></pre>
<p>或者可以通过浏览器访问<a href="https://master:8088">https://master:8088</a> 或者<a href="https://master:50070">https://master:50070</a> 查看 Hadoop 服务状态.</p>
<p><img src="/posts/2016/04/09/hadoop-2-7-2-single-node-and-cluster-mode-installation-guide/nodes-of-the-cluster.png" alt="Nodes of the cluster"> <img src="/posts/2016/04/09/hadoop-2-7-2-single-node-and-cluster-mode-installation-guide/data-node-information.png" alt="Namenode information"></p>
<p>P.S.关于<code>jps</code>命令. jps 位于 jdk 的 bin 目录下,其作用是显示当前系统的 java 进程情况,及其 id 号. jps 相当于 linux 进程工具 ps,但是不支持管道命令 grep jps 并不使用应用程序名来查找 JVM 实例.</p>
<h2>Trouble Shooting</h2>
<p>防跌坑指南. 记录了在 Hadoop 环境搭建过程中所遇到的坑</p>
<h3>Number of Live DataNode:0</h3>
<p>通过<code>start-dfs.sh</code>启动了 hadoop 多个节点的 datanode, 且通过<code>jps</code>命令能够看到正常的 datanode 和 resourcemanager 进程, 为什么 live datanode 数目为 0,或者只有 master 的那个 datanode?</p>
<p>可通过以下方法排除:</p>
<ol>
<li>关闭所有节点的防火墙(ubuntu): 先查看防火墙状态</li>
</ol>
<pre><code class="hljs bash">$ sudo ufw status
</code></pre>
<p>如果不是 disabled,则禁用</p>
<pre><code class="hljs bash">$ sudo ufw <span class="hljs-built_in">disable</span>
</code></pre>
<ol start="2">
<li>在 hadoop 服务运行的时候,关闭 namenode 的安全模式</li>
</ol>
<pre><code class="hljs bash">$ hadoop dfsadmin -safemode leave
</code></pre>
<ol start="3">
<li>在关闭 hadoop 服务的情况下,删除所有的日志文件,存储文件并重新 format 确保<code>hadoop_store</code>文件夹下的所有文件夹权限都是 777</li>
</ol>
<pre><code>$sudo rm -r /usr/local/hadoop/logs
$sudo rm -r /usr/local/hadoop_store/tmp
$sudo rm -r /usr/local/hadoop_store/hdfs
$sidp hdfs namenode -format
</code></pre>
<h2>References</h2>
<p>在环境搭建的过程中,参考了以下两篇文章: 其中 Apache 的官方 Wiki 文档写的真难读. 建议直接先看一遍 aws 的指南再动手.</p>
<p><a href="https://wiki.apache.org/hadoop/GettingStartedWithHadoop">https://wiki.apache.org/hadoop/GettingStartedWithHadoop</a> <a href="https://rstudio-pubs-static.s3.amazonaws.com/78508_abe89197267240dfb6f4facb361a20ed.html">https://rstudio-pubs-static.s3.amazonaws.com/</a></p>
</div><div data-v-48e13d92="" class="md-card-content"><div data-v-15189bc8="" data-v-48e13d92="" tabindex="0" class="md-chip md-theme-default md-clickable"><div class="md-ripple"><span data-v-15189bc8="" class=""> Hadoop </span> </div> <!----></div><div data-v-15189bc8="" data-v-48e13d92="" tabindex="0" class="md-chip md-theme-default md-clickable"><div class="md-ripple"><span data-v-15189bc8="" class=""> Linux </span> </div> <!----></div></div><div data-v-48e13d92="" class="md-card-content"><div data-v-7fa946ff="" data-v-48e13d92="" class="comment"><div data-v-7fa946ff="" id="disqus_thread"><iframe id="dsq-app1723" name="dsq-app1723" allowtransparency="true" frameborder="0" scrolling="no" tabindex="0" title="Disqus" width="100%" src="https://disqus.com/embed/comments/?base=default&amp;f=aquariuslt&amp;t_i=-posts-2016-04-09-hadoop-2-7-2-single-node-and-cluster-mode-installation-guide&amp;t_u=https%3A%2F%2Fblog.aquariuslt.com%2Fposts%2F2016%2F04%2F09%2Fhadoop-2-7-2-single-node-and-cluster-mode-installation-guide&amp;t_d=Hadoop%202.7.2%20%E5%8D%95%E8%8A%82%E7%82%B9%E4%B8%8E%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%20%7C%20Aquariuslt%20Blog&amp;t_t=Hadoop%202.7.2%20%E5%8D%95%E8%8A%82%E7%82%B9%E4%B8%8E%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%20%7C%20Aquariuslt%20Blog&amp;s_o=default#version=049b9d4c8356e0d7fe6487ff57f30ea3" style="width: 1px !important; min-width: 100% !important; border: none !important; overflow: hidden !important; height: 0px !important;"></iframe></div></div></div></div></div></div></div></div></main> <!----></div></div><script type="text/javascript" src="/js/chunk-vendors.d167db0b.js"></script><script type="text/javascript" src="/js/app.eff8a5d6.js"></script><iframe style="display: none;"></iframe></body></html>